version: "3.8"
services:
  gateway:
    build:
      context: ./gateway
    ports:
      - "8000:8000"
    env_file:
      - ./gateway/.env
    restart: unless-stopped
    # depends_on:
      # if you want to run Ollama side-by-side, uncomment below
      # - ollama

  # Optional: run Ollama in its own container
  # ollama:
  #   image: ghcr.io/ollama/ollama:latest
  #   ports:
  #     - "11434:11434"
  #   restart: unless-stopped
